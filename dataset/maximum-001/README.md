# Maximum Dataset

This is the largest dataset generated by CRUX (Cloud Resource mUtation eXtractor) from the Azure Quickstart Templates collection. It includes both positive (misconfigured) and negative (clean) samples for balanced ML training.

## Dataset Statistics

- **Templates processed**: 1,518 (792 Bicep + 726 ARM JSON)
- **Baseline resources**: 7,415 (unmutated, negative class)
- **Mutated resources**: 12,580 (with misconfigurations, positive class)
- **Total rows in CSV**: 19,995
- **Total label assignments**: 27,382
- **Unique label types**: 110
- **Class balance**: 62.9% positive / 37.1% negative
- **Property columns**: 24 (named, interpretable)

## Files

- `data.csv` - ML-ready dataset with named properties and binary labels
- `README.md` - This file

## CSV Schema

| Column | Description |
|--------|-------------|
| `resource_id` | Unique Azure resource identifier |
| `resource_type` | Azure resource type (e.g., Microsoft.Storage/storageAccounts) |
| `is_mutated` | Whether this resource was mutated (1) or baseline (0) |
| `mutation_id` | ID of the mutation applied (empty for baseline) |
| `mutation_severity` | Severity level (high, medium, low) |
| `has_misconfiguration` | Binary target: 1 if misconfigured, 0 if clean |
| `label_count` | Number of misconfiguration labels |
| `labels` | Comma-separated list of misconfiguration labels |
| `source_template` | Path to source template |
| Named properties | 24 security-relevant property columns (see below) |

## Named Property Columns

The dataset includes 24 interpretable property columns for statistical analysis:

**Storage Account:**
- `allowBlobPublicAccess`, `supportsHttpsTrafficOnly`, `minimumTlsVersion`
- `allowSharedKeyAccess`, `publicNetworkAccess`, `encryption_services_blob_enabled`

**Key Vault:**
- `enablePurgeProtection`, `enableSoftDelete`, `enableRbacAuthorization`

**Network:**
- `enableDdosProtection`, `securityRules`

**VM:**
- `osProfile_linuxConfiguration_disablePasswordAuthentication`
- `storageProfile_osDisk_encryptionSettings_enabled`

**General:**
- `location`, `sku_name`, `sku_tier`, `kind`

## Usage

### Python (Logistic Regression with statsmodels)

```python
import pandas as pd
import statsmodels.api as sm
import numpy as np

# Load dataset
df = pd.read_csv('data.csv')

# Select independent variables (IVs)
ivs = ['allowBlobPublicAccess', 'supportsHttpsTrafficOnly',
       'minimumTlsVersion', 'enablePurgeProtection',
       'enableSoftDelete', 'enableDdosProtection']

# Clean missing values
X = df[ivs].fillna(0)
y = df['has_misconfiguration']

# Add constant for intercept
X_const = sm.add_constant(X)

# Fit logistic regression
model = sm.Logit(y, X_const)
result = model.fit()

# Print statistical summary with coefficients and p-values
print(result.summary())

# Calculate odds ratios
odds_ratios = np.exp(result.params)
print("\nOdds Ratios:")
print(odds_ratios)
```

### R (ANOVA by Resource Type)

```r
library(tidyverse)

df <- read.csv('data.csv')

# One-way ANOVA: misconfiguration rate by resource type
anova_result <- aov(has_misconfiguration ~ resource_type, data = df)
summary(anova_result)

# Post-hoc Tukey test
TukeyHSD(anova_result)

# Logistic regression
model <- glm(has_misconfiguration ~ allowBlobPublicAccess + supportsHttpsTrafficOnly +
             minimumTlsVersion + enablePurgeProtection,
             data = df, family = binomial)
summary(model)
```

### Python (sklearn Random Forest)

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# Load dataset
df = pd.read_csv('data.csv')

# Use all named property columns as features
feature_cols = ['allowBlobPublicAccess', 'supportsHttpsTrafficOnly',
                'minimumTlsVersion', 'allowSharedKeyAccess',
                'publicNetworkAccess', 'enablePurgeProtection',
                'enableSoftDelete', 'enableDdosProtection',
                'location', 'sku_name', 'kind']

X = df[feature_cols].fillna(0).values
y = df['has_misconfiguration'].values

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Random Forest
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Evaluate
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))
```

## Reproduce This Dataset

To regenerate this dataset locally:

```bash
# 1. Clone the repository
git clone https://github.com/floatingsidewal/CRUX.git
cd CRUX

# 2. Install CRUX
pip install -e .[ml]

# 3. Fetch Azure Quickstart Templates
crux fetch-templates --output templates/

# 4. Generate the dataset
crux generate-dataset \
  --templates templates/azure-quickstart-templates \
  --pattern "**/*.bicep" \
  --include-arm-json \
  --rules rules/ \
  --output dataset/ \
  --name maximum-001

# 5. Export to CSV with named properties and baseline
crux export-csv \
  --dataset dataset/maximum-001 \
  --output dataset/maximum-001/data.csv \
  --include-baseline \
  --named-properties curated \
  --binary-mode any
```

## Generation Details

- **Generated**: 2025-12-13
- **CRUX version**: 2.0
- **Mutations**: 88 (across 8 resource types)
- **Rules**: 96 (CIS Benchmark aligned)
- **Binary mode**: `any` (positive if ANY misconfiguration detected)
- **Features**: Named properties (curated security-relevant)

## Label Categories

Labels are derived from CIS Azure Benchmark and custom security rules:

- **Storage**: Public access, weak TLS, insecure transfer, no encryption
- **Key Vault**: No purge protection, soft delete disabled, permissive access
- **VM**: Missing encryption, password auth enabled, no diagnostics
- **Network**: No NSG, public IPs without DDoS, insecure rules
- **App Service**: HTTP allowed, weak TLS, no authentication
- **Container Registry**: Admin enabled, public network access
- **Database**: Public access, no encryption, audit logging disabled
- **Load Balancer**: No health probes, insecure rules
