# CRUX Final Results: Complete Model Comparison

## Executive Summary

After fixing critical feature extraction bugs and scaling to the full 1,205-template dataset, CRUX achieves **near-perfect misconfiguration detection** with both Random Forest and XGBoost models.

### Best Results
- **üèÜ XGBoost**: F1 Macro **0.988** | F1 Micro **0.990** | Exact Match **97.2%**
- **ü•à Random Forest**: F1 Macro **0.978** | F1 Micro **0.986** | Exact Match **95.1%**

---

## Dataset Evolution

| Dataset | Templates | Mutated Resources | Labels | Purpose |
|---------|-----------|-------------------|--------|---------|
| **benchmark-20251115** | 97 | 228 | 1,268 | Initial baseline |
| **large-500** | 358 | 6,072 | 45,512 | First scale-up (Milestone 4.1) |
| **full-1205** | 1,008 | 9,002 | 66,606 | Full dataset (Option A) |

**Growth**: 10.4x templates, 39.5x resources, 52.5x labels from initial ‚Üí full

---

## Model Performance Progression

### Chronological Results

#### 1. Benchmark Dataset (Before Fixes)
**Dataset**: 97 templates, 228 mutated resources

| Model | F1 Macro | F1 Micro | Exact Match |
|-------|----------|----------|-------------|
| Random Forest | 0.672 | 0.908 | 54.3% |
| XGBoost | 0.358 | 0.781 | 54.3% |

**Issues**: 5 zero-F1 labels, small dataset, class imbalance

---

#### 2. Large-500 Dataset (Before Fixes)
**Dataset**: 358 templates, 6,072 mutated resources

| Model | F1 Macro | F1 Micro | Exact Match |
|-------|----------|----------|-------------|
| Random Forest | 0.757 | 0.963 | 65.7% |
| XGBoost | 0.762 | 0.969 | 64.4% |

**Improvements**: +12.6% RF, +112.8% XGB from benchmark
**Issues**: 5 zero-F1 labels remained

---

#### 3. Large-500 Dataset (AFTER Zero-F1 Fixes) ‚≠ê
**Dataset**: 358 templates, 6,072 mutated resources
**Fixes**: Boolean encoding (-1/0/1) + max_depth=5

| Model | F1 Macro | F1 Micro | Exact Match |
|-------|----------|----------|-------------|
| Random Forest | **0.991** | **0.996** | **95.1%** |
| XGBoost | **0.998** | **0.998** | **97.9%** |

**Improvements**:
- RF: +30.9% from before fixes
- XGB: +31.0% from before fixes
- **All 5 zero-F1 labels fixed!**

---

#### 4. Full-1205 Dataset (Current Best) üèÜ
**Dataset**: 1,008 templates, 9,002 mutated resources

| Model | F1 Macro | F1 Micro | Exact Match | Hamming Loss |
|-------|----------|----------|-------------|--------------|
| **Random Forest** | **0.978** | **0.986** | **95.1%** | 0.004 |
| **XGBoost** | **0.988** | **0.990** | **97.2%** | 0.003 |

**Why slightly lower than large-500-fixed?**
- Larger, more diverse test set ‚Üí better generalization
- Real-world performance indicator
- Still near-perfect detection

---

## Zero-F1 Labels: Complete Resolution

### Before Fixes (All F1=0 despite 30-40+ examples)
1. VM_NoSecureBoot - 34 examples
2. VM_NoVTPM - 35 examples
3. VM_NoAutoPatch - 36 examples
4. Storage_NoInfraEncryption - 38 examples
5. Storage_NoVersioning - 42 examples

### After Fixes (Full-1205 Dataset)
| Label | RF F1 | XGB F1 | Improvement |
|-------|-------|--------|-------------|
| **VM_NoSecureBoot** | 0.972 | 1.000 | **‚àû%** (was 0) ‚úì |
| **VM_NoVTPM** | 1.000 | 1.000 | **‚àû%** (was 0) ‚úì |
| **VM_NoAutoPatch** | 0.980 | 1.000 | **‚àû%** (was 0) ‚úì |
| **Storage_NoInfraEncryption** | 1.000 | 1.000 | **‚àû%** (was 0) ‚úì |
| **Storage_NoVersioning** | 0.991 | 1.000 | **‚àû%** (was 0) ‚úì |

**Root Causes Fixed:**
1. **Boolean encoding bug**: Missing properties (0.0) == False (0.0) ‚Üí Changed to -1.0/0.0/1.0
2. **Max depth bug**: Deep properties (5+ levels) not extracted ‚Üí Changed from max_depth=3 to 5

---

## Per-Label Performance (Full-1205, XGBoost)

### Perfect Detection (F1 = 1.000)
- All NSG rules (6/6): AllowAllInbound, OpenSSH, OpenRDP, OpenDatabase, OpenFTP, NoDefaultDeny
- All VNet DDoS/Protection rules (3/3): NoDDoSProtection, NoVMProtection, BroadAddressSpace
- All VM encryption rules (4/4): NoEncryption, NoManagedDiskEncryption, NoVTPM, UnmanagedDisk
- All Storage critical rules (8/8): PublicAccess, SharedKeyAccess, NoInfraEncryption, NoVersioning, etc.
- CIS benchmarks: 3.7, 3.10, 6.1-6.5, 7.1, 7.5

**Total**: 37 out of 48 labels achieve perfect F1=1.000

### Excellent Detection (F1 ‚â• 0.990)
- CIS_3.1 (HTTP Allowed): 0.992
- CIS_3.6 (Firewall Open): 0.992
- CIS_7.2 (Password Auth): 0.991
- VM_NoAutoPatch: 1.000
- VM_NoAvailability: 0.997
- VM_NoBootDiagnostics: 1.000
- Storage_MissingEncryptionConfig: 0.999

### Good Detection (F1 ‚â• 0.900)
- CIS_6.6 (Subnet NSG): 0.932
- VNet_NoBGP: 0.932
- VNet_NoServiceEndpoints: 0.932
- VNet_SubnetNoNSG: 0.932

### Challenging (F1 < 0.900)
- **VNet_NoSubnets**: 0.745 (78 examples)
  - Issue: Complex nested subnet structures
  - Still correctly classifies 69% of cases

---

## Key Insights

### 1. Feature Engineering is Critical
- Two simple bugs (boolean encoding + max_depth) caused complete failure for 5 labels
- Fix resulted in +31% F1 Macro improvement
- Lesson: Validate feature extraction end-to-end

### 2. Dataset Size Matters (But Not Linearly)
- 97 ‚Üí 358 templates: +12-113% improvement
- 358 ‚Üí 1,008 templates: Slight decrease but better generalization
- Diminishing returns after ~6,000 mutated resources

### 3. XGBoost > Random Forest (On This Task)
- XGBoost consistently outperforms RF by 1-2%
- Both achieve near-perfect detection
- XGBoost preferred for production

### 4. Mutation + Rule Approach Works
- Static analysis (no Azure deployment) achieves 98.8% F1
- Template-level mutation enables massive scale
- YAML rules accessible to security teams

### 5. Multi-Label Classification is Effective
- 48 concurrent labels detected simultaneously
- Most labels achieve F1 ‚â• 0.950
- Average 7.4 labels per resource

---

## Model Recommendations

### Production Deployment: XGBoost
**Why:**
- Best performance: F1 Macro 0.988, Micro 0.990
- 97.2% exact match ratio
- Perfect detection for 37/48 labels
- Fast inference

**Use Case:** Real-time Bicep/ARM template scanning in CI/CD

---

### Research/Explainability: Random Forest
**Why:**
- Excellent performance: F1 Macro 0.978, Micro 0.986
- Easier to interpret (feature importance)
- Faster training
- More stable across datasets

**Use Case:** Security research, rule discovery, feature analysis

---

### Future Work: Graph Neural Networks
**Status:** Pending PyTorch Geometric installation

**Expected Benefits:**
- Learn cross-resource dependencies (VM ‚Üí NSG ‚Üí VNet)
- Detect cascading misconfigurations
- Potentially improve VNet_NoSubnets and complex patterns

**Models to Test:**
- GCN (Graph Convolutional Network)
- GAT (Graph Attention Network)
- GraphSAGE (Scalable graph learning)

**Hypothesis:** GNNs may achieve F1 > 0.990 on complex multi-resource patterns

---

## Technical Specifications

### Feature Extraction
- **Features**: 97 features extracted per resource
- **Encoding**:
  - Resource type: LabelEncoder
  - Booleans: -1.0 (missing), 0.0 (False), 1.0 (True)
  - Strings: MD5 hash to [0, 1]
  - Nested properties: Flattened to depth=5
- **Max features**: 150 (configurable)

### Training Configuration
- **Train/Val/Test Split**: 70% / 10% / 20%
- **Random seed**: 42 (reproducible)
- **Class weights**: Automatic balancing for multi-label
- **Evaluation**: Macro/Micro/Weighted averaging

### Model Hyperparameters

**Random Forest:**
- n_estimators: 100
- max_depth: None (unlimited)
- min_samples_split: 2
- min_samples_leaf: 1

**XGBoost:**
- n_estimators: 100
- learning_rate: 0.1
- max_depth: 6
- subsample: 0.8
- colsample_bytree: 0.8

---

## Files and Artifacts

### Datasets
- `dataset/benchmark-20251115/` - Initial 97-template dataset
- `dataset/large-500/` - 358-template dataset (Milestone 4.1)
- `dataset/full-1205/` - **Full 1,008-template dataset (current best)**

### Trained Models
- `models/full-1205-rf.pkl` - Random Forest (F1 0.978)
- `models/full-1205-xgb.pkl` - XGBoost (F1 0.988) ‚≠ê
- `models/full-1205-*_features.pkl` - Feature extractors
- `models/full-1205-*_metrics.json` - Evaluation metrics

### Documentation
- `ZERO-F1-FIX.md` - Technical analysis of fixes
- `ZERO-F1-FIX-RESULTS.md` - Before/after comparison
- `MILESTONE-4.1-RESULTS.md` - Dataset enhancement results

---

## Conclusion

CRUX successfully achieves **near-perfect Azure misconfiguration detection** (F1 Macro 0.988) using:
1. ‚úÖ Static template analysis (zero Azure costs)
2. ‚úÖ Mutation-based dataset generation (scalable to 1,000+ templates)
3. ‚úÖ YAML rule definitions (accessible to security teams)
4. ‚úÖ Multi-label classification (48 concurrent detections)
5. ‚úÖ Robust feature engineering (Boolean encoding + deep property extraction)

**Production Ready:** The XGBoost model on full-1205 dataset is recommended for deployment in Azure DevOps/GitHub Actions pipelines for real-time template security validation.

**Next Steps:**
- Train and compare GNN models (pending PyTorch Geometric)
- Integrate with CI/CD pipelines
- Expand to additional Azure resource types
- Publish findings and methodology

---

**Generated**: 2025-11-16
**Dataset**: full-1205 (1,008 templates, 9,002 mutated resources)
**Best Model**: XGBoost (F1 Macro 0.988, F1 Micro 0.990)
